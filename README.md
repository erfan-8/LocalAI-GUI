# LocalAI-GUI
A sleek PyQt6-powered local ChatGPT UI using Ollama, with support for streaming, code highlighting, and persistent conversations.
# ðŸ’» LocalAI-GUI

A sleek, offline ChatGPT-style desktop app using **Ollama** and **PyQt6**.  
This app lets you interact with local LLMs in real-time with chat history, markdown/code highlighting, and full control over UI.

---

## âœ¨ Features

- âœ… PyQt6-based modern GUI
- âœ… Local LLM inference via [Ollama](https://ollama.com)
- âœ… Real-time streaming of model responses
- âœ… Syntax highlighting for code blocks
- âœ… Persistent multi-chat storage (as JSON)
- âœ… Font size settings & dark theme
- âœ… "Stop" button to interrupt long replies
- âœ… Lightweight and private (no cloud dependency)

---

## ðŸ§° Technologies Used

- Python 3.10+
- PyQt6
- Ollama (local LLM backend)
- HTML formatting & JSON storage

---

## ðŸ“¸ Screenshot

*(Insert screenshot of your app UI here)*

---

## ðŸš€ Getting Started

### 1. Clone the Repo

```bash
git clone https://github.com/erfan-8/LocalAI-GUI.git
cd LocalAI-GUI
```

# 2. Create and Activate a Virtual Environment
